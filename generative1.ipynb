{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os \nimport torchvision.transforms as transforms\nfrom torchvision.transforms.functional import to_pil_image\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport torch\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nos.makedirs('./data',exist_ok=True)\npath2data = './data'\ndev = 'cuda' if torch.cuda.is_available() else 'cpu'\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-21T18:58:04.932372Z","iopub.execute_input":"2021-12-21T18:58:04.932728Z","iopub.status.idle":"2021-12-21T18:58:04.942991Z","shell.execute_reply.started":"2021-12-21T18:58:04.932685Z","shell.execute_reply":"2021-12-21T18:58:04.940485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nh, w = 64, 64\nmean = (0.5, 0.5, 0.5)\nstd = (0.5, 0.5, 0.5) \ntransform= transforms.Compose([\n    transforms.Resize((h,w)),\n    transforms.CenterCrop((h,w)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)]\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:04.944487Z","iopub.execute_input":"2021-12-21T18:58:04.944876Z","iopub.status.idle":"2021-12-21T18:58:04.952424Z","shell.execute_reply.started":"2021-12-21T18:58:04.944838Z","shell.execute_reply":"2021-12-21T18:58:04.951671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\ntrain_ds = datasets.STL10(path2data,download=True,transform=transform)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:04.953682Z","iopub.execute_input":"2021-12-21T18:58:04.954342Z","iopub.status.idle":"2021-12-21T18:58:08.771374Z","shell.execute_reply.started":"2021-12-21T18:58:04.954304Z","shell.execute_reply":"2021-12-21T18:58:08.769818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x,_ in train_ds:\n    print(x.shape , x.min(),x.max())\n    break\nimage = to_pil_image(0.5*x+0.5)#std mean\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:08.772459Z","iopub.status.idle":"2021-12-21T18:58:08.773089Z","shell.execute_reply.started":"2021-12-21T18:58:08.772818Z","shell.execute_reply":"2021-12-21T18:58:08.772843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = torch.utils.data.DataLoader(train_ds,batch_size=32,shuffle=True)\nfor x,y in train_dl:\n    print(y)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:08.774694Z","iopub.status.idle":"2021-12-21T18:58:08.775642Z","shell.execute_reply.started":"2021-12-21T18:58:08.775399Z","shell.execute_reply":"2021-12-21T18:58:08.775424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as tf\nimport torch.nn as nn\nclass Generator(nn.Module):\n    def __init__(self,params):\n        super(Generator,self).__init__()\n        nz = params[\"nz\"]\n        ngf = params[\"ngf\"]\n        noc = params[\"noc\"]\n        self.dconv1 = nn.ConvTranspose2d(nz,ngf*8,kernel_size=4,stride=1,padding=0,bias=False) # ngf*8 fitlers\n        self.bn1    = nn.BatchNorm2d(ngf*8) #number of features \n        \n        self.dconv2 = nn.ConvTranspose2d(ngf*8,ngf*4,kernel_size=4,stride=2,padding=1,bias=False) # ngf*8 fitlers\n        self.bn2    = nn.BatchNorm2d(ngf*4) #number of features \n        \n        self.dconv3 = nn.ConvTranspose2d(ngf*4,ngf*2,kernel_size=4,stride=2,padding=1,bias=False) # ngf*8 fitlers\n        self.bn3    = nn.BatchNorm2d(ngf*2) #number of features \n        \n        self.dconv4 = nn.ConvTranspose2d(ngf*2,ngf,kernel_size=4,stride=2,padding=1,bias=False) # ngf*8 fitlers\n        self.bn4    = nn.BatchNorm2d(ngf) #number of features \n        \n        self.dconv5 = nn.ConvTranspose2d(ngf,noc,kernel_size=4,stride=2,padding=1,bias=False) # ngf*8 fitlers\n        self.bn5    = nn.BatchNorm2d(noc) #number of features \n    def forward(self,x):\n        x = tf.relu(self.bn1(self.dconv1(x)))\n        x = tf.relu(self.bn2(self.dconv2(x)))\n        x = tf.relu(self.bn3(self.dconv3(x)))\n        x = tf.relu(self.bn4(self.dconv4(x)))\n        x = tf.relu(self.bn5(self.dconv5(x)))\n        out = torch.tanh(x)\n        return out\nparams = {'nz' : 100,\n          'ngf': 64,\n          'noc':3}\nmodel_gen = Generator(params).to(device=dev)\nwith torch.no_grad():\n    y= model_gen(torch.zeros(1,100,1,1, device=dev))\n    print(y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:08.776733Z","iopub.status.idle":"2021-12-21T18:58:08.777661Z","shell.execute_reply.started":"2021-12-21T18:58:08.777422Z","shell.execute_reply":"2021-12-21T18:58:08.777446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self,params):\n        super(Discriminator,self).__init__()\n        nic= params[\"nic\"]\n        ndf = params[\"ndf\"]\n        self.conv1 = nn.Conv2d(nic,ndf,kernel_size=4,stride=2,padding=1,bias=False) # ngf*8 fitlers\n        self.bn1    = nn.BatchNorm2d(ndf) #number of features \n        \n        self.conv2 = nn.Conv2d(ndf,ndf*2,kernel_size=4,stride=2,padding=1,bias=False) # ngf*8 fitlers\n        self.bn2    = nn.BatchNorm2d(ndf*2) #number of features \n        \n        self.conv3 = nn.Conv2d(ndf*2,ndf*4,kernel_size=4,stride=2,padding=1,bias=False) # ngf*8 fitlers\n        self.bn3    = nn.BatchNorm2d(ndf*4) #number of features \n        \n        self.conv4 = nn.Conv2d(ndf*4,ndf*8,kernel_size=4,stride=2,padding=1,bias=False) # ngf*8 fitlers\n        self.bn4    = nn.BatchNorm2d(ndf*8) #number of features \n        \n        self.conv5 = nn.Conv2d(ndf*8,1,kernel_size=4,stride=1,padding=0,bias=False) # ngf*8 fitlers\n    def forward(self,x):\n        x = tf.leaky_relu(self.bn1(self.conv1(x)),0.2,inplace=True)\n        x = tf.leaky_relu(self.bn2(self.conv2(x)),0.2,inplace=True)\n        x = tf.leaky_relu(self.bn3(self.conv3(x)),0.2,inplace=True)\n        x = tf.leaky_relu(self.bn4(self.conv4(x)),0.2,inplace=True)\n        x = self.conv5(x)\n        out = torch.sigmoid(x)\n        return out.view(-1)\nparams_dis = { \"nic\": 3,\"ndf\": 64}\nmodel_dis = Discriminator(params_dis)\nmodel_dis.to(dev) \nprint(model_dis)\nwith torch.no_grad():\n    y= model_dis(torch.zeros(1,3,h,w, device=dev))\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:08.778939Z","iopub.status.idle":"2021-12-21T18:58:08.779351Z","shell.execute_reply.started":"2021-12-21T18:58:08.779132Z","shell.execute_reply":"2021-12-21T18:58:08.779154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_weights(model):\n    classname = model.__class__.__name__ \n    if classname.find('Conv') != -1:\n        nn.init.normal_(model.weight.data, 0.0, 0.02)#init conv and dconv mean 0 std 0.02\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(model.weight.data, 1.0, 0.02)\n        nn.init.constant_(model.bias.data, 0)\n\nmodel_dis.apply(initialize_weights)\nmodel_gen.apply(initialize_weights)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:08.780639Z","iopub.status.idle":"2021-12-21T18:58:08.781047Z","shell.execute_reply.started":"2021-12-21T18:58:08.780834Z","shell.execute_reply":"2021-12-21T18:58:08.780856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_func = nn.BCELoss()\nopt_gen = torch.optim.Adam(model_gen.parameters(),lr=2e-4,betas=(0.5,0.9999))\nopt_dis = torch.optim.Adam(model_dis.parameters(),lr=2e-4,betas=(0.5,0.9999))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:08.782501Z","iopub.status.idle":"2021-12-21T18:58:08.782913Z","shell.execute_reply.started":"2021-12-21T18:58:08.782683Z","shell.execute_reply":"2021-12-21T18:58:08.782714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_label = 1\nfake_label = 0\nnz = params[\"nz\"]\nloss_history={\"gen\": [], \"dis\": []}\nnum_epoch = 100\nfor epoch in range(num_epoch):\n    for xb,yb in train_dl:\n        bz = xb.shape[0]\n        xb = xb.to(device=dev)\n        yb = torch.full((bz,),real_label,device=dev,dtype=torch.float32)\n        model_dis.zero_grad()#same as loss_func zero_grad\n        out_dis = model_dis(xb)\n        loss_r = loss_func(out_dis,yb)\n        loss_r.backward()\n        \n        noise = torch.randn(bz, nz, 1, 1, device=dev)\n        out_gen = model_gen(noise)\n        out_dis = model_dis(out_gen.detach())\n        yb.fill_(fake_label)\n        loss_f = loss_func(out_dis,yb)\n        loss_f.backward()\n        loss_dis = loss_r + loss_f\n        opt_dis.step()\n        \n        model_gen.zero_grad() \n        yb.fill_(real_label)\n        out_dis = model_dis(out_gen) \n        loss_gen = loss_func(out_dis, yb)\n        loss_gen.backward() \n        opt_gen.step()\n        loss_history[\"gen\"].append(loss_gen.item())\n        loss_history[\"dis\"].append(loss_dis.item()) \n    print(epoch)\n\n\nimport os\npath2models = \"./models/\"\nos.makedirs(path2models, exist_ok=True)\npath2weights_gen = os.path.join(path2models, \"weights_gen.pt\")\npath2weights_dis = os.path.join(path2models, \"weights_dis.pt\")\ntorch.save(model_gen.state_dict(), path2weights_gen)\ntorch.save(model_dis.state_dict(), path2weights_dis)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:08.784297Z","iopub.status.idle":"2021-12-21T18:58:08.784701Z","shell.execute_reply.started":"2021-12-21T18:58:08.784484Z","shell.execute_reply":"2021-12-21T18:58:08.784507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    fixed_noise = torch.randn(16, nz, 1, 1, device=dev) \n    img_fake = model_gen(noise)[0].detach().cpu()\nimage = to_pil_image(img_fake*0.5+0.5)\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T19:00:41.910428Z","iopub.execute_input":"2021-12-21T19:00:41.910978Z","iopub.status.idle":"2021-12-21T19:00:42.106699Z","shell.execute_reply.started":"2021-12-21T19:00:41.91094Z","shell.execute_reply":"2021-12-21T19:00:42.105928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'h'","metadata":{"execution":{"iopub.status.busy":"2021-12-21T18:58:14.47124Z","iopub.execute_input":"2021-12-21T18:58:14.472006Z","iopub.status.idle":"2021-12-21T18:58:14.4788Z","shell.execute_reply.started":"2021-12-21T18:58:14.471959Z","shell.execute_reply":"2021-12-21T18:58:14.478086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}