{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/abbaseldor/localization?scriptVersionId=86462100\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport seaborn as sns\n%matplotlib inline\nimport os\nimport numpy as np\nfrom PIL import Image, ImageDraw\nimport matplotlib.pylab as plt\nimport torch\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\npath2data = '../input/challamd/Training400/'\ndevice='cuda'\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-29T10:14:32.866931Z","iopub.execute_input":"2022-01-29T10:14:32.867711Z","iopub.status.idle":"2022-01-29T10:14:32.877821Z","shell.execute_reply.started":"2022-01-29T10:14:32.867663Z","shell.execute_reply":"2022-01-29T10:14:32.87713Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2022-01-29T10:14:34.893973Z","iopub.execute_input":"2022-01-29T10:14:34.894301Z","iopub.status.idle":"2022-01-29T10:14:44.1437Z","shell.execute_reply.started":"2022-01-29T10:14:34.894265Z","shell.execute_reply":"2022-01-29T10:14:44.1429Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting openpyxl\n  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n\u001b[K     |████████████████████████████████| 242 kB 888 kB/s eta 0:00:01\n\u001b[?25hCollecting et-xmlfile\n  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\nInstalling collected packages: et-xmlfile, openpyxl\nSuccessfully installed et-xmlfile-1.1.0 openpyxl-3.0.9\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"path2labels = os.path.join(path2data,'Fovea_location.xlsx') #path to training data\nlabels = pd.read_excel(path2labels)\nlabels.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:11:32.890064Z","iopub.execute_input":"2022-01-19T19:11:32.890636Z","iopub.status.idle":"2022-01-19T19:11:32.986639Z","shell.execute_reply.started":"2022-01-19T19:11:32.890579Z","shell.execute_reply":"2022-01-19T19:11:32.985656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AorN = [imn[0] for imn in labels.imgName] # distribution \nsns.scatterplot(x=labels.Fovea_X,y=labels.Fovea_Y,hue=AorN)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:11:37.319235Z","iopub.execute_input":"2022-01-19T19:11:37.320162Z","iopub.status.idle":"2022-01-19T19:11:37.830279Z","shell.execute_reply.started":"2022-01-19T19:11:37.320123Z","shell.execute_reply":"2022-01-19T19:11:37.828832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(labels_ds,id):\n    label = labels_ds.values[id]\n    image_prefix ='AMD' if label[1][0] == 'A' else 'Non-AMD'\n    image = Image.open(os.path.join(path2data,image_prefix,label[1]))\n    x = label[2]\n    y = label[3]\n    label = (x,y)\n    return image,label\nimage,(x,y) = load_image(labels,5) #test\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:13:41.789536Z","iopub.execute_input":"2022-01-19T19:13:41.790223Z","iopub.status.idle":"2022-01-19T19:13:42.861072Z","shell.execute_reply.started":"2022-01-19T19:13:41.790184Z","shell.execute_reply":"2022-01-19T19:13:42.859892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Draw_image(image,x,y,w=300,h=300,line_width=1):# utility function to rectangle on target ares\n    draw = ImageDraw.Draw(image)\n    draw.rectangle(((x-w/2,y-h/2),(x+w/2,y+h/2)),width=line_width,outline='green')\n    return np.asarray(image)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:14:05.322277Z","iopub.execute_input":"2022-01-19T19:14:05.323016Z","iopub.status.idle":"2022-01-19T19:14:05.332187Z","shell.execute_reply.started":"2022-01-19T19:14:05.322964Z","shell.execute_reply":"2022-01-19T19:14:05.330856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms.functional as TF\ndef img_resize(image,labels,target_size=(256,256)): #resize images and label\n    x,y = labels\n    o_w,o_h = image.size\n    t_w,t_h = target_size\n    n_img = TF.resize(image,target_size)\n    n_labels = (x*(t_w/o_w),y*(t_h/o_h))\n    return n_img,n_labels","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:07.708137Z","iopub.execute_input":"2022-01-19T20:02:07.708573Z","iopub.status.idle":"2022-01-19T20:02:07.719246Z","shell.execute_reply.started":"2022-01-19T20:02:07.708532Z","shell.execute_reply":"2022-01-19T20:02:07.717193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def horizontal_flip(image,labels):\n    w,h = image.size\n    x,y = labels\n    image = TF.hflip(image)\n    labels = (w-x,y)\n    return image,labels","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:14:09.423383Z","iopub.execute_input":"2022-01-19T19:14:09.424531Z","iopub.status.idle":"2022-01-19T19:14:09.431963Z","shell.execute_reply.started":"2022-01-19T19:14:09.424485Z","shell.execute_reply":"2022-01-19T19:14:09.430808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scale_label(label,image_size):#normilize label\n    div = [ai/bi for ai,bi in zip(label,image_size)]\n    return div","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:14:11.459244Z","iopub.execute_input":"2022-01-19T19:14:11.459566Z","iopub.status.idle":"2022-01-19T19:14:11.466101Z","shell.execute_reply.started":"2022-01-19T19:14:11.459532Z","shell.execute_reply":"2022-01-19T19:14:11.464696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rescale_label(label,image_size):# rescale label to original size\n    div = [ai*bi for ai,bi in zip(label,image_size)]\n    return div","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:14:13.205287Z","iopub.execute_input":"2022-01-19T19:14:13.205606Z","iopub.status.idle":"2022-01-19T19:14:13.210951Z","shell.execute_reply.started":"2022-01-19T19:14:13.205572Z","shell.execute_reply":"2022-01-19T19:14:13.209785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vertical_flip(image,labels):\n    w,h = image.size\n    x,y = labels\n    image = TF.vflip(image)\n    labels = x,w-y\n    return image,labels","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:14:14.980176Z","iopub.execute_input":"2022-01-19T19:14:14.981206Z","iopub.status.idle":"2022-01-19T19:14:14.988147Z","shell.execute_reply.started":"2022-01-19T19:14:14.981147Z","shell.execute_reply":"2022-01-19T19:14:14.987111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def translate(image,labels,max_translation=(0.2,0.2)):\n    w,h = image.size\n    x,y = labels\n    max_t_w,max_t_h = max_translation\n    trans_coff_x= np.random.rand()*2-1\n    trans_coff_y= np.random.rand()*2-1\n    x_t = int(trans_coff_x*max_t_w*w)\n    y_t = int(trans_coff_y*max_t_h*h)\n    image = TF.affine(image,translate=(x_t,y_t),angle=0,shear=0,scale=1)\n    labels = (x+x_t,y+y_t)\n    return image,labels\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:14:17.221651Z","iopub.execute_input":"2022-01-19T19:14:17.222305Z","iopub.status.idle":"2022-01-19T19:14:17.231173Z","shell.execute_reply.started":"2022-01-19T19:14:17.222268Z","shell.execute_reply":"2022-01-19T19:14:17.22965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transformer(image,label,params): #data augmentation transformer // randomly apply transformation functions\n    image,label = img_resize(image,label,params['target_size'])\n    if np.random.rand()<params['p_hflip']:\n        image,label = horizontal_flip(image,label)\n    if np.random.rand()<params['p_hflip']:\n        image,label = horizontal_flip(image,label)\n    if np.random.rand()<params['p_shift']:\n        image,label = translate(image,label,params['max_translation'])\n    label = scale_label(label,params['target_size'])\n    return image,label","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:13.04906Z","iopub.execute_input":"2022-01-19T20:02:13.049873Z","iopub.status.idle":"2022-01-19T20:02:13.058309Z","shell.execute_reply.started":"2022-01-19T20:02:13.049834Z","shell.execute_reply":"2022-01-19T20:02:13.056833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random \nimg, label=load_image(labels,1)\nparams={\n    \"target_size\" : (256, 256), \"p_hflip\" : .0,\n    \"p_vflip\" : .0,\n    \"p_shift\" : 1.0, \"max_translation\": (0.2, 0.2),\n}\nimg_t,label_t=transformer(img,label,params)# testing transformer \nlabel_t = rescale_label(label_t,params['target_size'])\nprint(label_t)\nimage = Draw_image(img_t,*label_t,w=30,h=30,line_width=3)\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:32.527454Z","iopub.execute_input":"2022-01-19T20:02:32.528297Z","iopub.status.idle":"2022-01-19T20:02:32.926665Z","shell.execute_reply.started":"2022-01-19T20:02:32.528258Z","shell.execute_reply":"2022-01-19T20:02:32.925657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sanity check\nids = [250, 260 ,270]\nfor i,_id in enumerate(ids):\n    image,(x,y) = vertical_flip(*img_resize(*load_image(labels,_id),target_size=(250,250)))\n    plt.figure(figsize = (15,15))\n    plt.subplot(3,3,i+1)\n    img = Draw_image(image,x,y,w=50,h=50,line_width=1)\n    plt.imshow(img)\n    plt.title(labels.values[_id,1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:37.432969Z","iopub.execute_input":"2022-01-19T20:02:37.433274Z","iopub.status.idle":"2022-01-19T20:02:38.513645Z","shell.execute_reply.started":"2022-01-19T20:02:37.43324Z","shell.execute_reply":"2022-01-19T20:02:38.51268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#custom dataset\nfrom torch.utils.data import Dataset \nclass AMD_Dataset(Dataset):\n    def __init__(self,path2data,transform=0,transform_params=0):\n        self.transformer = transformer\n        self.transformer_params = transform_params\n        path2labels = os.path.join(path2data,'Fovea_location.xlsx')\n        labels_pd   = pd.read_excel(path2labels,index_col = 'ID')\n        self.labels = labels_pd[['Fovea_X','Fovea_Y']].values\n        self.ids    = labels_pd.index\n        imgsName  = labels_pd['imgName']\n        self.path2images = np.zeros(len(self.ids),dtype=object)\n        for _id in self.ids:\n            img_name = imgsName[_id]\n            prefix = 'AMD' if img_name[0] =='A' else 'Non-AMD'\n            image_path = os.path.join(path2data,prefix,img_name)\n            self.path2images[_id-1] = image_path\n    def __len__(self):\n        return len(self.ids)\n    def __getitem__(self,idx):\n        image = Image.open(self.path2images[idx])\n        label = self.labels[idx]\n        image, label = self.transformer(image,label,self.transformer_params)\n        return np.asarray(image).transpose(2,0,1),label\ndata = AMD_Dataset(path2data=path2data,transform_params={\n    \"target_size\" : (256, 256), \"p_hflip\" : .0,\n    \"p_vflip\" : .0,\n    \"p_shift\" : 0, \"max_translation\": (0.2, 0.2),\n})","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:42.496063Z","iopub.execute_input":"2022-01-19T20:02:42.496949Z","iopub.status.idle":"2022-01-19T20:02:42.676884Z","shell.execute_reply.started":"2022-01-19T20:02:42.496911Z","shell.execute_reply":"2022-01-19T20:02:42.675892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split data \nfrom torch.utils.data import Subset\nfrom sklearn.model_selection import ShuffleSplit\nss = ShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\nindices = range(len(data))\nfor train_index,val_index in ss.split(indices):\n    train_sub = Subset(data,train_index) # creating training subet \n    val_sub = Subset(data,val_index)# creating validation subet ","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:45.333391Z","iopub.execute_input":"2022-01-19T20:02:45.334271Z","iopub.status.idle":"2022-01-19T20:02:45.343637Z","shell.execute_reply.started":"2022-01-19T20:02:45.334232Z","shell.execute_reply":"2022-01-19T20:02:45.342118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport torch\ntrain_dl = DataLoader(train_sub,batch_size=8,shuffle=True)\nfor img,label in train_dl:\n    print(img.shape)\n    label = torch.stack(label,1)\n    print(label)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:46.625112Z","iopub.execute_input":"2022-01-19T20:02:46.625424Z","iopub.status.idle":"2022-01-19T20:02:47.629689Z","shell.execute_reply.started":"2022-01-19T20:02:46.625388Z","shell.execute_reply":"2022-01-19T20:02:47.628614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# U-net model\nimport torch.nn as nn\nimport torch.nn.functional as F\nclass Net(nn.Module):\n    def __init__(self,params={'input_channels':3,'initial_filter':16,'number_out':2}):\n        super(Net,self).__init__()\n        C_in = params['input_channels']\n        init_f = params['initial_filter']\n        num_outputs = params['number_out']\n        self.conv1 = nn.Conv2d(C_in,init_f,kernel_size=3,padding=1,stride=2)\n        self.conv2 = nn.Conv2d(C_in+init_f,  2*init_f,kernel_size=3,padding=1,stride=1)\n        self.conv3 = nn.Conv2d(C_in+init_f*3,4*init_f,kernel_size=3,padding=1,stride=1)\n        self.conv4 = nn.Conv2d(C_in+init_f*7,8*init_f,kernel_size=3,padding=1,stride=1)\n        self.conv5 = nn.Conv2d(C_in+init_f*15,16*init_f,kernel_size=3,padding=1,stride=1)\n        self.fcl   = nn.Linear(16*init_f,num_outputs)\n\n    def forward(self,x):\n        identity = F.avg_pool2d(x,kernel_size = 4)\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x,2)\n        x = torch.cat((x,identity),dim=1)\n        \n        identity = F.avg_pool2d(x,kernel_size = 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x,2)\n        x = torch.cat((x,identity),dim=1)\n        \n        identity = F.avg_pool2d(x,kernel_size = 2)\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x,2)\n        x = torch.cat((x,identity),dim=1)\n        \n        identity = F.avg_pool2d(x,kernel_size = 2)\n        x = F.relu(self.conv4(x))\n        x = F.max_pool2d(x,2)\n        x = torch.cat((x,identity),dim=1)\n        \n        x = F.relu(self.conv5(x))\n        \n        x = F.adaptive_avg_pool2d(x,1)\n        x = torch.flatten(x,start_dim=1)\n        x = self.fcl(x)\n        return x\nmodel = Net()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:49.955334Z","iopub.execute_input":"2022-01-19T20:02:49.955638Z","iopub.status.idle":"2022-01-19T20:02:49.98394Z","shell.execute_reply.started":"2022-01-19T20:02:49.955604Z","shell.execute_reply":"2022-01-19T20:02:49.982857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cxcy2box(cxcy,w=50./256,h=50./256): # convert label from x ,y to box\n    w_tensor = (torch.ones(cxcy.shape[0],1)*w).to(device=device)\n    h_tensor = (torch.ones(cxcy.shape[0],1)*h).to(device=device)\n    w_h = torch.cat((w_tensor,h_tensor),1)\n    X_Y_min = cxcy-w_h/2\n    X_Y_max = cxcy+w_h/2\n    return torch.cat((X_Y_min,X_Y_max),1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import optim\noptimizer = optim.Adam(model.parameters(),lr=3e-4)\ndef get_lr(opt):\n    return opt.param_groups[0]['lr']\ncurrent_lr = get_lr(optimizer)\nprint('current lr = {}'.format(current_lr))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:15:14.909974Z","iopub.execute_input":"2022-01-19T19:15:14.910294Z","iopub.status.idle":"2022-01-19T19:15:14.917761Z","shell.execute_reply.started":"2022-01-19T19:15:14.910259Z","shell.execute_reply":"2022-01-19T19:15:14.916502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reduce learning rate on Plateau\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau \nscheduler = ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=20,verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:15:16.842786Z","iopub.execute_input":"2022-01-19T19:15:16.843187Z","iopub.status.idle":"2022-01-19T19:15:16.850901Z","shell.execute_reply.started":"2022-01-19T19:15:16.84314Z","shell.execute_reply":"2022-01-19T19:15:16.849435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_func = nn.SmoothL1Loss(reduction='sum') # define loss function","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:15:19.163325Z","iopub.execute_input":"2022-01-19T19:15:19.163665Z","iopub.status.idle":"2022-01-19T19:15:19.1699Z","shell.execute_reply.started":"2022-01-19T19:15:19.163629Z","shell.execute_reply":"2022-01-19T19:15:19.16875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:15:21.579649Z","iopub.execute_input":"2022-01-19T19:15:21.58052Z","iopub.status.idle":"2022-01-19T19:15:21.58785Z","shell.execute_reply.started":"2022-01-19T19:15:21.580482Z","shell.execute_reply":"2022-01-19T19:15:21.586733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define metric as area over union\nimport torchvision\ndef metrics_batch(output,target):\n    output = cxcy2box(output)\n    target = cxcy2box(target)\n    iou=torchvision.ops.box_iou(output, target) \n    return torch.diagonal(iou, 0).sum().item()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:15:23.559258Z","iopub.execute_input":"2022-01-19T19:15:23.560122Z","iopub.status.idle":"2022-01-19T19:15:23.566939Z","shell.execute_reply.started":"2022-01-19T19:15:23.560082Z","shell.execute_reply":"2022-01-19T19:15:23.565419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_batch(loss_func, output, target, opt=None):\n    loss = loss_func(output,target)\n    with torch.no_grad():\n        metric = metrics_batch(output,target)\n    if opt is not None: # update network's weights \n        opt.zero_grad()\n        loss.backward() \n        opt.step()\n    return loss.item(),metric\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:15:25.764026Z","iopub.execute_input":"2022-01-19T19:15:25.764331Z","iopub.status.idle":"2022-01-19T19:15:25.771116Z","shell.execute_reply.started":"2022-01-19T19:15:25.764298Z","shell.execute_reply":"2022-01-19T19:15:25.769951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epoch \ndef loss_epoch(model,loss_func,train_dl,val_dl=None,opt=None): \n    running_loss = 0\n    running_metric =0\n    len_data = len(train_dl)\n    c=0\n    for x,y in train_dl:\n        c=c+1\n        y = torch.stack(y,1).to(device=device)\n        output = model(x.double().to(device=device))\n        loss,metric = loss_batch(loss_func,output,y,opt)\n        running_loss += loss\n    running_loss = running_loss/float(len_data)\n    running_metric = running_metric/float(len_data)\n    return loss , metric","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:56.692381Z","iopub.execute_input":"2022-01-19T20:02:56.692694Z","iopub.status.idle":"2022-01-19T20:02:56.700621Z","shell.execute_reply.started":"2022-01-19T20:02:56.692661Z","shell.execute_reply":"2022-01-19T20:02:56.699097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = optim.Adam(model.parameters(), lr=1e-5) # Adan optimizer\nlr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)\nmodel = model.double()\nmodel.cuda()\nloss_history= []\nmetric_history= []\nfor i in range(40):\n    print(f'Epoch number {i}')\n    loss,metric = loss_epoch(model,loss_func,train_dl,opt=opt)\n    loss_history.append(loss)\n    metric_history.append(metric)\n    print(f'epoch loss = {loss}')\n    print(f'metric = {metric}')    \n# train and validate the model\n#model,loss_hist,metric_hist=train_val(model,params_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:02:58.341749Z","iopub.execute_input":"2022-01-19T20:02:58.342183Z","iopub.status.idle":"2022-01-19T20:03:05.235971Z","shell.execute_reply.started":"2022-01-19T20:02:58.342137Z","shell.execute_reply":"2022-01-19T20:03:05.234043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimgs =0\nfor imgs,label in train_dl:\n    label = torch.stack(label,1)\n    predic = model(imgs.double().to(device))\n    print(predic*256)\n    print(label*256)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:54:44.553523Z","iopub.execute_input":"2022-01-19T19:54:44.553845Z","iopub.status.idle":"2022-01-19T19:54:45.35079Z","shell.execute_reply.started":"2022-01-19T19:54:44.55381Z","shell.execute_reply":"2022-01-19T19:54:45.34978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training validation loss\nplt.plot(loss_history, 'r')  \nplt.plot(metric_history, 'b') \nplt.legend('loss')","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:54:48.751559Z","iopub.execute_input":"2022-01-19T19:54:48.752183Z","iopub.status.idle":"2022-01-19T19:54:49.06228Z","shell.execute_reply.started":"2022-01-19T19:54:48.752145Z","shell.execute_reply":"2022-01-19T19:54:49.061312Z"},"trusted":true},"execution_count":null,"outputs":[]}]}